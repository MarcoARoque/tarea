{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac62d85-4835-4a8b-a5d1-d25571ab6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marco Roque\n",
    "# Cris Chavez\n",
    "# Omar Alonso Martinez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce300898-dd5a-455e-b0e6-833ec1e4eab9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: flask in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from flask) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests flask pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d17cec2-5bd9-4f68-bdb2-224fcf38475c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "301dfa10-509c-483a-b667-506299144117",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754a7512-292e-4c22-99a8-36a71e769bfd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c6ee42-2181-4f8a-9f2d-dc51c3fa53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ee9ccb-c705-4a95-894f-2d6a784194f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1691ff1c-0b06-4f37-8a66-10c491a20ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datos= {\n",
    "    'rating': [ 5,5,5,5,1,5,5,5,5,5,5,5,5,5,5,1,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,2,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,1,4,4,5,5,5,5,5,5,5,5,5,1,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,3,5,5,5,5,5,5,3,5],\n",
    "    'title': [ ' Great gift',' amazon gift card',' perfect gift',' Nice looking',' Not $10 Gift Cards',' Cute!',' Easy gift',' Great gift',' Gifts for my two granddaughters',' Great for saying u201cthank youu201d to the mail person farrier, yard man, etc',' Convenient safe and perfect gift',' Giftcard',' Simple giftcard!',' Great giftcard',' Easy..',' One Star',' Great Product.',' No note attached to sent gift card',' Gift card',' Good',' Good Product',' Good Product',' Good Product',' Good Product',' Good Product',' Good product',' Good product',' Good Product',' Good Product',' Good',' Gift card',' So easy',' Mistake',' Great gift idea',' Secure',' Birthday surprise!',' Birthday Gift',' Fun',' Reload is super easy.',' Convenience of giftabiliy.',' Great Gift Package',' Grest Sandwitches !!',' GOOD PIZZA !!',' We like this Store and they stock Tons of different Items for all kinds of Pets',' Money was loaded on card',' ud83dudc4d',' Love it!!',' Five Stars',' So cool you can get a free tin with the gift ...',' Reccomend',' Little sister surprise',' The added value was great but no more',' Perfect gift!',' Great staff appreciation gift!',' Cute cute cute!',' Five Stars',' As described.',' Perfect gift for any occasion. Let them pick out what they love!',' 12 year old daughter loved this gift!',' Easy to send to an Amazon shopper',' Recd promo from Amazon when reloading gift card.',' Saves a Little Over time.',' What a great company',' A problem to use at drive thrus',' A gift card does make a great gift for a tweenager.',' Nice to have',' Excellent Gift',' Yay so easy!',')',' 10/10',' Perfect for a birthday ud83cudf82',' Perfect!',' Gift box nice!',' It was soooo easy',' great',' Amazon Thinks of Everything!',' Amazon lover giftee?  Buy it!',' Timing',' Was easy to do',' PENGUINS',' Believe this is the best gift to give !',' convenient',' Five Stars',' Best gift for someone you donu2019t know what to get',' Great value',' Sweet gift!',' Amazing',' Great Holder',' Gift card',' Starbuck gift card',' Good litte thank-you gifts',' Okay as a gift',' Good gift',' So convenient.',' Just what was ordered.',' Can Do It From Home',' Love it!',' Easy to use',' Easy to use',' Perfect gift sent I a lovely container'],\n",
    "    'text': [' Having Amazon money is always good.',' Always the perfect gift.  I have never given one and had someone seem or act disappointed.  Just the opposite.  They are thrilled and excited to have a bit of a spree.  Always the perfect size and color!  Arrives in 1 day in most cases.  So its never too late!  Lots of cards to chose from... thank you... birthday... wedding..baby..  and many that work for many occasions...',' When you have a person who is hard to shop for.. an amazon gift card is P E R F E C T.  Man or woman...  No matter what their hobby... lifestyle.. or age.  All you have to do is pick the $.  Dont forget to mention that it is a GIFT when you check out - you will have some gift card options.  Ive ordered many of these over years.  They are always received with glee.  Woo hoo!  If youre looking for a great fit for me - this is just my size!  )  Best to all!','The tin is a nice touch and pretty large.  Its about 434 in diameter and about 1234 thick.  I added a pretty red ribbon and it is perfect.  Who doesnt love shopping on Amazon? Arrived quickly I have Prime... but I think they ship the gift cards out SUPER fast... like over night. In case you need it for a FAST gift.','I bought this pack of Starbucks Gift cards in 2019. Ive given them to friends and I gave 2 to my daughter.My daughter used one recently and it had 6.52 on the card not $10.00. She had the cashier check the balance of the other card and it had $5.32 on it! She had forgotten that she had these gift cards so yes 2 years later decided to use the when she found them! Do they decline in value? And then both had random amounts on them! Im embarrassed now to have given them as gifts! Friends receiving the gift card arent going to tell you that werent able to cover their order with the card you gave them!!!',' That snowman tin is adorable',' Great and easy gift', 'Super cute nice quality tin Your choose amount',' They love it !!', 'So many people Make your life better so remember them!',' My grandson inlaw loves his gift cards so its the perfect gift for Christmas',' What can you say about a gift card? Well, it was valid. Its a good gift for someone who doesnt like to cook. Arrived promptly.',' Easy way to gift money for birthdays.',' Great gift for online shoppers!',' Reloading is easy. Shopping is easy. Amazon is easy.',' Card did not work!!!!',' I bought this for a Christmas gift.The recipient really liked it.',' What a pretty gift card presentation the recipient loved it ! I have one complaint  I took the time and wrote a short note to the recipient of the gift card so she knew who and why the GC was being sent but the note wasnu2019t attached. Iu2019ve used the option to write a note on many occasions and several times it showed up without the note . I actually had to contact her to ask if she had checked her mail knowing it had arrived .',' Perfect! Arrived just when stated!',' Good gift card',' Good Product',' Good Product',' Good Product',' Good Product',' Good Product',' Good product',' Good product',' Good Product',' Good Product',' Good',' Perfect for Christmas',' Easy to do',' Hit button by mistake n deduction from credit card on file',' Always great to order from my home. Amazon rocks!',' So easy to use and recipients get to choose how to use it.',' This was a good birthday surprise!',' Have given as Holiday Birthday  Other Occasions remembrances. Always appreciated by the person receiving.',' Awesome  they work',' Really ready to reload gift cards.',' A great way to give a gift to family members in physical form. It was so convenient.',' Nice gift packaging for any event',' Perfect and I even used Amazon Points - was mailed right out.',' Perfect and I even used Amazon Points - was mailed right out.',' Our cats love this place.',' Was cute and the money was loaded when it arrived', 'ud83dudc4d', 'This is an online gift card nothing to show sorryud83eudd2a',' Gift cards are always a hit.',' So cool you can get a free tin with the gift card and it comes in 24 hours!! Super awesome. Last year I just printed off the gift cards which looked kind of cheap even though the cards were for substantial amounts. Highly recommend.',' Really easy to load',' Same gift as her big sisters, this little one can choose the exact thing she most desires and run to the door for three days in anticipation.  A combined birthday and Christmas present for one who knows her own mind.  Good choice!',' Purchasing an Amazon gift card came with an added monetary value but no more.A Bronx cheer for you!',' This is near where I work and has a drive through.  Nothing better during these times to give than a gift of good food they can pick up with minimal contact. Gift cards are the way to go these days!',' What better gift during these times than one to treat yourself.  This is a great gift I gave out to my staff and even those who dont read liked the idea of being able to listen to the audiobooks as well as there being content and other media through Audible.',' I love the tin! The gift cards can be ordered on different amounts.',' Simple and easy.',' Being able to reload the gift card is a time saver.',' I mean really, who wouldnt LOVE this?!?  Wonderful gift for any occasion.',' Perfect gift for your kids!',' This is a simple gift to friends or family. For me it was easy to setup. Took ok only about 30 seconds. I also redeem Visa gifts by giving the gift card to myself. I like there isnt a fee. I do want Amazon to make some cooler cards with my animation when a receiver gets it.',' Bonus, recd a promo from Amazon for reloading gift card.  Yeah.<br ><br >Gift card was posted to my account quickly.',' Nice way to save a few bucks overtime by reloading your own gift card.',' Who wouldnt want an Amazon gift card?  The box foretold the contents, lol.',' I only used the $50 card one time at Burger King. It was difficult to use. Must be run as credit, not as gift card. No remaining balance is given at the end of the transaction. And although its on me, I misplaced or lost this card after only spending about $6 of it. I was hoping that the seller could provide me with the full card number so that I could at least use it online for other purchases. They failed to respond. I have the receipt from BK, but it only shows the last 4 numbers. There isnt a way of contacting happy cards customer service online that I could figure out. I wish Id just stuck with credit cards. A lot safer.',' We all know the kid who wants nothing. Or actually wants everything but nothing is good enough. YES,YES,the secret weapon. A AMAZON GIFT CARD!!  You pulled it off. You showed your love and you are the best and greatest. Happy Birthday to just because,You are the BEST!!',' This comes in  very handy, and makes the guilt less',' Who would not like an Amazon Gift Card?  Makes everyone I give them, happy!',' So easy! No scraping!',' easy to use',' works great',' Another nice gift box from Amazon. With the world the way it is now I had to send a gift rather than going to a party. And Amazon has a good selection of gift boxes and fast shipping so my nephew was happy when he received the card in the mail.',' Bought this for a gift and was very happy it shipped quickly and they received it just in time! Amazon is awesome! ud83eudd29',' Love the gift box. So much j NB icee than just handing a gift card to the grandkids.',' It was a nice way to give a present',' great buy',' GREAT idea!  I was so happy to have these on hand for the Holidays!', 'So gift card for certain sum.  No service fee.  Lively metal gift box - yes..... I said metal.  What is not to love about this???!<br ><br >Well done Amazon.  Well done.',' Great timing.',' Easy to use',' So so cute!',' The recipient can choose what they want so the giver has less chance of a mistake.',' A great and convenient gift idea-price is right too!', 'The gift card came in a pretty box.<br >Thanks Amozan.',' This was for a gift',' Made my shopping much better good value',' I sent this to my brother and he couldnt stop talking about it. This boxes puts a little more nice into a gift. Very pretty!',' It can be used for a variety of things.',' Great holder for gift cards',' Makes these so easy for any holiday and especially stops buying something people do not like',' My friend like the gift card like the sweater for holiday card',' Im happy they did not cost me more than their face value to buy. I gave them out as a nice thank you to those who helped me with small things around my house. I sent them in the mail as a surprise, knowing money or gifts was not necessary. I recommend them.',' After I bought several I realized I could have sent gift money via text without the fees or wait.',' Those who already have everything, they can buy an audible book, an old rerun of a favorite movie, some little thing they may want, or whatever as a gift for any occasion. I recommend.',' Arrived on time, in perfect shape, and best of all the person receiving the gift can buy whatever they want. One size fits all!',' Made holiday shopping easy!', 'Usually I either receive an Amazon gift card as a birthday andor Christmas gift or I purchase them at a store. Then its very easy to add the amount to my gift card balance using my cell phone. Well I was stuck inside for several days due to a blizzard and I bought quite a few books then due to a travel ban I could not go to the store to purchase a gift card.<br >So after checking my Gift Card Balance I saw that I had overindulged and it needed to be topped up. One of the options under Manage Your Balance was to Reload Your Balance. I had never used this option but decided to try it. It was so easy to do and I didnt have to leave the comfort of my home. I will be using it again in the future.',' Love my card!!', 'Itu2019s easy to use and very convenient. I would definitely consider refill more in the future',' Very easy to use. I wish I knew about it earlier',' Sent in a lovely container'],\n",
    "    'asin':['B00IX1I3G6', 'B005ESMMWW', 'B01K8RIM5Y', 'B0091JKVU0', 'B00FTGTM5E', 'B072L7GTF5', 'B00IX1I3G6', 'B072P5VV4D', 'B072P5VV4D', 'B071NM2PNL', 'B01GKWEH64', 'B084RMVP59', 'B07HJHK8Y5', 'B0866T1TQJ', 'B00IX1I3G6', 'B00X6G8WCI', 'B01K8RMDO0', 'B01IE42ST4', 'B06W5SBSL7', 'B078VSWVGY', 'B072F9T6VX', 'B01C9MW8Z6', 'B072BQ7XSH', 'B01IE42ST4', 'B07HJD9FVV', 'B07HJHK8Y5', 'B00BXLWD0U', 'B01MSBQB1P', 'B01K8RMDO0', 'B07PFLG7VG', 'B07FK7L976', 'B00IX1I3G6', 'B00IX1I3G6', 'B01K8RL9C2', 'B01K8RL9C2', 'B01C9MW8Z6', 'B077T9WSSN', 'B01MSBQB1P', 'B00IX1I3G6', 'B071NM2PNL', 'B014S24J16', 'B00CIECDEM', 'B00HLAO738', 'B015726JLY', 'B076CV42TK', 'B07HJHK8Y5', 'B086KKT3RX', 'B0091JKY0M', 'B072P5VV4D', 'B00IX1I3G6', 'B0091JKYLQ', 'B00IX1I3G6', 'B07Q8KN5TJ', 'B07Y5YJK66', 'B01C9MW8Z6', 'B00IX1I3G6', 'B086KKT3RX', 'B01MDLOM4V', 'B005ESMHN6', 'B00IX1I3G6', 'B00IX1I3G6', 'B00IX1I3G6', 'B005ESMF5G', 'B07RN957Q8', 'B00IX1I3G6', 'B00IX1I3G6', 'B071NM2PNL', 'B00IX1I3G6', 'B086KKT3RX', 'B00IX1I3G6', 'B06ZY43PDR', 'B07FKKBFHS', 'B01K8RIM5Y', 'B086KKT3RX', 'B005ESMGZU', 'B00IT0NO10', 'B0866QM41K', 'B00IX1I3G6', 'B086KKT3RX', 'B07FKK8SFR', 'B0866QM41K', 'B01MSBQB1P', 'B005ESMM04', 'B07641P3WL', 'B07674CBVT', 'B07DDC8FJM', 'B07HJD9FVV', 'B07FK7L976', 'B07HJHK8Y5', 'B076ZTSX5V', 'B00FTGTM5E', 'B07GH6WX29', 'B07FMJVVKW', 'B07HJHK8Y5', 'B00IX1I3G6', 'B086KKT3RX', 'B00IX1I3G6', 'B086KKT3RX', 'B00IX1I3G6', 'B01K8RJDEI'],\n",
    "    'parent_asin':['B00IX1I3G6', 'B005ESMMWW', 'B005S28ZES', 'B00ADR2LV6', 'B00FTGTIOE', 'B00ADR2LV6', 'B00IX1I3G6', 'B00ADR2LV6', 'B00ADR2LV6', 'B071X4ZX3X', 'B01GKWEEQM', 'B07YYWDPSM', 'B07HJHK8Y5', 'B077N4CNVJ', 'B00IX1I3G6', 'B00X6G8J3A', 'B077N4CNVJ', 'B0BT85F69N', 'B071X4ZX3X', 'B00BXLW5QC', 'B018F4M89S', 'B00JFBLZ90', 'B072BQ7XSH', 'B0BT85F69N', 'B07HJD9FVV', 'B07HJHK8Y5', 'B00BXLWCJ2', 'B01MSBQB1P', 'B077N4CNVJ', 'B00VTVA1T4', 'B00ADR2LV6', 'B00IX1I3G6', 'B00IX1I3G6', 'B018F4H5DM', 'B018F4H5DM', 'B00JFBLZ90', 'B071X4ZX3X', 'B01MSBQB1P', 'B00IX1I3G6', 'B071X4ZX3X', 'B018F4M89S', 'B00BXLW5QC', 'B00HLAO65M', 'B00BXLVETG', 'B076CV42TK', 'B07HJHK8Y5', 'B086KKT3RX', 'B0091JKY0M', 'B00ADR2LV6', 'B00IX1I3G6', 'B0091JKYLQ', 'B00IX1I3G6', 'B07Q8KCGYT', 'B07Y5YJK66', 'B00JFBLZ90', 'B00IX1I3G6', 'B086KKT3RX', 'B01B3DYSF0', 'B005ESMHN6', 'B00IX1I3G6', 'B00IX1I3G6', 'B00IX1I3G6', 'B005ESMF5G', 'B07JMV25V6', 'B00IX1I3G6', 'B00IX1I3G6', 'B071X4ZX3X', 'B00IX1I3G6', 'B086KKT3RX', 'B00IX1I3G6', 'B071LMFYTG', 'B07FKKBFHS', 'B005S28ZES', 'B086KKT3RX', 'B005ESMGZU', 'B00IT0NO10', 'B00ADR2LV6', 'B00IX1I3G6', 'B086KKT3RX', 'B07FKK8SFR', 'B00ADR2LV6', 'B01MSBQB1P', 'B005ESMM04', 'B07641P3WL', 'B00OV98120', 'B073VBZM8J', 'B07HJD9FVV', 'B00ADR2LV6', 'B07HJHK8Y5', 'B00BXLW2AQ', 'B00FTGTIOE', 'B07GH6WX29', 'B077N4CNVJ', 'B07HJHK8Y5', 'B00IX1I3G6', 'B086KKT3RX', 'B00IX1I3G6', 'B086KKT3RX', 'B00IX1I3G6', 'B00ADR2LV6'],\n",
    "    'user_id':['AHZ6XMOLEWA67S3TX7IWEXXGWSOA', 'AFZUK3MTBIBEDQOPAK3OATUOUKLA', 'AFZUK3MTBIBEDQOPAK3OATUOUKLA', 'AFZUK3MTBIBEDQOPAK3OATUOUKLA', 'AH5L7ILVA6HYLZOUZIQAWNHVVK3A', 'AECABX3OO3GK7FCPZLFM3LT2E6UA', 'AFSCQMP2EPYLGJN7OBTMEXCBE2OQ', 'AF4XAUOI5XPGWHCPOTORKBIJSRDA', 'AGJXTLEOLLTIX5AAGFPBZ7CNNVOQ', 'AG7QDTQYHFOIXFWSVUUBZOEIW2NA', 'AGVVUU3QRQBHNASSGI5YQLPYOI2Q', 'AH4O5W3EM4CKQGHMBVTSPCJRYF7Q', 'AG3BG6PCNVQKVYNWHT7IJHEKUQAA', 'AG3BG6PCNVQKVYNWHT7IJHEKUQAA', 'AFO3G62P2JXCNMWZTAIB56KPG56A', 'AEMW2ADCJBXXCQLXQVM3RJEK53TQ', 'AECK3BJSJOAFSKAAUD4ILDFXZ7KQ', 'AH5ZBPCVWAAGJCOPLXMFXD7PGIJQ', 'AFWK5HW3FB4HNVYJUHU5ZW7NPCYA', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFDMZ4TRX3HXQQUGWAHJQTIF65BQ', 'AFEJKJ56OD6H2XH55DGHJI2526MA', 'AEINWALDRYT4NTF3M5NC2WZ5YQNA', 'AHVPSZCUQH3UMQCGQSDZ7BZVUHNQ', 'AFPHKIJFGIU4G4POXRFCEF5RJJHA', 'AGQSSZPF5DTU56OIYEZVVKTMKJIQ', 'AHHKNZRXSHRMSGS4WZU4G2XUFF6A', 'AGOXD3ECHHH2XAFGO6TSSMRZJQVQ', 'AEMM65JNJARUZ23W4LY7737WXIXQ', 'AG57CQ6P4QWYMWUV6MTAOETUKHTA', 'AEN7KAKQJGIQCNK6NMVWH2WZ3YXQ', 'AG3VXRJ5OUQDF3UAEOEIIZ6Z5Z3A', 'AG3VXRJ5OUQDF3UAEOEIIZ6Z5Z3A', 'AG3VXRJ5OUQDF3UAEOEIIZ6Z5Z3A', 'AG3VXRJ5OUQDF3UAEOEIIZ6Z5Z3A', 'AHYARJU3M2CYM3W5SZYL33KOFVHA', 'AEG6UV72JH6WOHEAWLMNXT6J7F4A', 'AFZ2WFNVLG46EXHEF5AEG4LNR5JQ', 'AHYPJP7HKAXKK2QZG3MRPVNHUQGQ', 'AET5VFNIYKIHIPO3ZALZSLXX3KOQ', 'AF76P2AWQWB7ZDCNGZO2GV7JIK4Q', 'AFEYY6TB5DOF2U4WCL7GRMNZREJA', 'AEE2PYYDXJGV6ZO3YHZBBEMSUG4Q', 'AHNGFLCHE75OQH4PZFLNJTTKUBSQ', 'AHNGFLCHE75OQH4PZFLNJTTKUBSQ', 'AFTPWW67O3POISX7RO75HMRHQL3Q', 'AEZJ2TU2SLZEDP2YXEM7UHTLM6EA', 'AF2FG45QSSVK2WMLTGPTD5IZHSWA', 'AF36B77ISO4OHA5GUTF46F4BJRMQ', 'AF36B77ISO4OHA5GUTF46F4BJRMQ', 'AGV5IAI7ELBBT327V7EUBECMW6MQ', 'AFOU3KAJIZ7YQCXJ3CJOYJ3J7GSQ', 'AGO3H7RLCHVCCYG44FAHDBYPUA4Q', 'AGO3H7RLCHVCCYG44FAHDBYPUA4Q', 'AHZ53K26WSCRDR32EGBBA43OEFFA', 'AFOELOYLQUGV6UDAZU2YLAOVZ4JA', 'AFICQHAE6YOEIGE5TYZG5TN7OTRQ', 'AGSGQ6Z2XBJPLC5C2EOZDPCDXKDQ', 'AHCDZ4OXU7U4AWYCAK2674R3NYVQ', 'AF4WLLHTQLRPEZ33OJDYG23MFLKQ', 'AF4WLLHTQLRPEZ33OJDYG23MFLKQ', 'AFV22L7AEKI2LW6HMLRLUKNYVBGQ', 'AFV22L7AEKI2LW6HMLRLUKNYVBGQ', 'AHUX7LYUKBTCPVVALKMMPH6JYCGQ', 'AETXMYPV6KHWTNVRXNXFYQN2TZNA', 'AFDAN27KWZQOMPX5J2NB7MAPOIXA', 'AHI5GVBI6PNSQ4T43RTEAJ4VQH2A', 'AGWX2VRM6GYPGQM3XNL2NEYY7JAQ', 'AFTDSPCG32FV2VPWLEYPDQARTSQA', 'AFH37SUSDVJI6GWNF2YSSGAPUB7A', 'AEVH6SVYTFNNONWKJLLZOGDRBFWQ', 'AE5PZITMWZJBPVKL7XXYUFBTITQA', 'AEUZHPIGXLWEQ7HW5LRYEPD3QYCQ', 'AG4H4WHLCUIJMCIRGXUZWNVIOODA', 'AFP4PCVJ723ZNLOS4IPWVLLC3T2Q', 'AFGNK6IBETT72HOGGHE7GMBDWPQA', 'AGF6GWDAWG7UW3R5O2G5O5JZC4BQ', 'AG4DEQCBVNCJPRHXC3S255BBJALQ', 'AE5GHFQZ6IXM4QNYTLTYJO24KQZQ', 'AFAE5TN6ZBXFPCM7ROQKDHZKNZNA', 'AFAE5TN6ZBXFPCM7ROQKDHZKNZNA', 'AFMHO73ZLBHUMB36EHB4GUFLM3SA', 'AFMHO73ZLBHUMB36EHB4GUFLM3SA', 'AFMHO73ZLBHUMB36EHB4GUFLM3SA', 'AFMHO73ZLBHUMB36EHB4GUFLM3SA', 'AFMHO73ZLBHUMB36EHB4GUFLM3SA', 'AFQW7QX2DREMFPK5WSMQKG27UOQA', 'AG6K7GPCDHQNKMVDMTYKKWSOAVVQ', 'AFGDRVPCP742YM5MMLFIKZCGNNRQ', 'AFGDRVPCP742YM5MMLFIKZCGNNRQ', 'AFWAXSLBIVNLLSKAKEXZWH6ZRFIQ'],\n",
    "    'timestamp': [1.54987E+12,1.59988E+12,1.53594E+12,1.41844E+12,1.63807E+12,1.60866E+12,1.6021E+12,1.55125E+12,1.67539E+12,1.67431E+12,1.574E+12,1.5975E+12,1.62279E+12,1.62279E+12,1.46637E+12,1.50561E+12,1.54509E+12,1.58887E+12,1.56063E+12,1.65264E+12,1.6472E+12,1.64357E+12,1.62587E+12,1.62179E+12,1.61861E+12,1.61032E+12,1.61032E+12,1.601E+12,1.59462E+12,1.59462E+12,1.64636E+12,1.58706E+12,1.57619E+12,1.60718E+12,1.61705E+12,1.57859E+12,1.66189E+12,1.54795E+12,1.55403E+12,1.60827E+12,1.47222E+12,1.45903E+12,1.45903E+12,1.44942E+12,1.55941E+12,1.64262E+12,1.67003E+12,1.4906E+12,1.5144E+12,1.61375E+12,1.48668E+12,1.63816E+12,1.60437E+12,1.60437E+12,1.52771E+12,1.51345E+12,1.64324E+12,1.49672E+12,1.49179E+12,1.56093E+12,1.57182E+12,1.55823E+12,1.48428E+12,1.6159E+12,1.66715E+12,1.50171E+12,1.61144E+12,1.49497E+12,1.65319E+12,1.58292E+12,1.58929E+12,1.58649E+12,1.62155E+12,1.67208E+12,1.47751E+12,1.4203E+12,1.66853E+12,1.59538E+12,1.66334E+12,1.56202E+12,1.64185E+12,1.54369E+12,1.43322E+12,1.55449E+12,1.54552E+12,1.6465E+12,1.66585E+12,1.6766E+12,1.57567E+12,1.51589E+12,1.65309E+12,1.64143E+12,1.62948E+12,1.6176E+12,1.57739E+12,1.67295E+12,1.5152E+12,1.6409E+12,1.5934E+12,1.63779E+12],\n",
    "    'helpful_vote': [0,0,27,0,2,0,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,4,0,0,0,1,0,0,1,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,17,0,0,0,0],\n",
    "    'verified_purchase': [ True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, False, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
    "  \n",
    "}\n",
    "\n",
    "df= pd.DataFrame(datos)\n",
    "df.to_csv('DatosLimpios.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff1a791-b54d-41ea-b942-098e526e453b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b874d18-667c-418c-a34b-f7674532ee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rating                                 title  \\\n",
      "0        5                            great gift   \n",
      "1        5                      amazon gift card   \n",
      "2        5                          perfect gift   \n",
      "3        5                          nice looking   \n",
      "4        1                      not 10 gift card   \n",
      "..     ...                                   ...   \n",
      "95       5                   can do it from home   \n",
      "96       5                               love it   \n",
      "97       5                           easy to use   \n",
      "98       3                           easy to use   \n",
      "99       5  perfect gift sent i lovely container   \n",
      "\n",
      "                                                 text        asin parent_asin  \\\n",
      "0                  having amazon money is always good  B00IX1I3G6  B00IX1I3G6   \n",
      "1   always the perfect gift i have never given one...  B005ESMMWW  B005ESMMWW   \n",
      "2   when you have person who is hard to shop for a...  B01K8RIM5Y  B005S28ZES   \n",
      "3   the tin is nice touch and pretty large it abou...  B0091JKVU0  B00ADR2LV6   \n",
      "4   i bought this pack of starbucks gift card in i...  B00FTGTM5E  B00FTGTIOE   \n",
      "..                                                ...         ...         ...   \n",
      "95  usually i either receive an amazon gift card a...  B086KKT3RX  B086KKT3RX   \n",
      "96                                       love my card  B00IX1I3G6  B00IX1I3G6   \n",
      "97  itu2019s easy to use and very convenient i wou...  B086KKT3RX  B086KKT3RX   \n",
      "98    very easy to use i wish i knew about it earlier  B00IX1I3G6  B00IX1I3G6   \n",
      "99                           sent in lovely container  B01K8RJDEI  B00ADR2LV6   \n",
      "\n",
      "                         user_id     timestamp  helpful_vote  \\\n",
      "0   AHZ6XMOLEWA67S3TX7IWEXXGWSOA  1.549870e+12             0   \n",
      "1   AFZUK3MTBIBEDQOPAK3OATUOUKLA  1.599880e+12             0   \n",
      "2   AFZUK3MTBIBEDQOPAK3OATUOUKLA  1.535940e+12            27   \n",
      "3   AFZUK3MTBIBEDQOPAK3OATUOUKLA  1.418440e+12             0   \n",
      "4   AH5L7ILVA6HYLZOUZIQAWNHVVK3A  1.638070e+12             2   \n",
      "..                           ...           ...           ...   \n",
      "95  AFQW7QX2DREMFPK5WSMQKG27UOQA  1.672950e+12            17   \n",
      "96  AG6K7GPCDHQNKMVDMTYKKWSOAVVQ  1.515200e+12             0   \n",
      "97  AFGDRVPCP742YM5MMLFIKZCGNNRQ  1.640900e+12             0   \n",
      "98  AFGDRVPCP742YM5MMLFIKZCGNNRQ  1.593400e+12             0   \n",
      "99  AFWAXSLBIVNLLSKAKEXZWH6ZRFIQ  1.637790e+12             0   \n",
      "\n",
      "    verified_purchase  \n",
      "0                True  \n",
      "1               False  \n",
      "2                True  \n",
      "3               False  \n",
      "4                True  \n",
      "..                ...  \n",
      "95               True  \n",
      "96               True  \n",
      "97               True  \n",
      "98               True  \n",
      "99               True  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.DataFrame(datos)\n",
    "def preprocesar_texto(texto):\n",
    "  tokens = word_tokenize(texto.lower())\n",
    "    \n",
    "  stop_words = set(stopwords.words('spanish'))\n",
    "  tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "  return ' '.join(tokens)\n",
    "\n",
    "df['title'] = df['title'].apply(preprocesar_texto)\n",
    "df['text'] = df['text'].apply(preprocesar_texto)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46298f6-38f8-44a4-bd8b-6db7960752f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.9\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.30      0.33      0.32        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importar Bibliotecas Necesarias\n",
    "#import pandas as pd\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df['title'])\n",
    "y = df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3a344a-aa9a-41aa-b198-5619ac5c59d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4657b69d-e290-4e81-9c6d-599b61c70d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/scikit-learn/\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c624136-4c9c-48f8-8a4b-1bfc85b654bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Bibliotecas Necesarias\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b889f9ba-82be-4566-832b-407a0d7a616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar recursos necesarios de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22fcfcc0-a760-4f7c-8ed3-d7497c59d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                  Great gift\n",
      "1                            amazon gift card\n",
      "2                                perfect gift\n",
      "3                                Nice looking\n",
      "4                          Not $10 Gift Cards\n",
      "                       ...                   \n",
      "95                        Can Do It From Home\n",
      "96                                   Love it!\n",
      "97                                Easy to use\n",
      "98                                Easy to use\n",
      "99     Perfect gift sent I a lovely container\n",
      "Name: title, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame(datos)\n",
    "df['title'] \n",
    "print(df['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a88c97-4b07-4c59-a481-21fedefa54f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rating                                 title  \\\n",
      "0        5                            great gift   \n",
      "1        5                      amazon gift card   \n",
      "2        5                          perfect gift   \n",
      "3        5                          nice looking   \n",
      "4        1                      not 10 gift card   \n",
      "..     ...                                   ...   \n",
      "95       5                   can do it from home   \n",
      "96       5                               love it   \n",
      "97       5                           easy to use   \n",
      "98       3                           easy to use   \n",
      "99       5  perfect gift sent i lovely container   \n",
      "\n",
      "                                                 text        asin parent_asin  \\\n",
      "0                  having amazon money is always good  B00IX1I3G6  B00IX1I3G6   \n",
      "1   always the perfect gift i have never given one...  B005ESMMWW  B005ESMMWW   \n",
      "2   when you have person who is hard to shop for a...  B01K8RIM5Y  B005S28ZES   \n",
      "3   the tin is nice touch and pretty large it abou...  B0091JKVU0  B00ADR2LV6   \n",
      "4   i bought this pack of starbucks gift card in i...  B00FTGTM5E  B00FTGTIOE   \n",
      "..                                                ...         ...         ...   \n",
      "95  usually i either receive an amazon gift card b...  B086KKT3RX  B086KKT3RX   \n",
      "96                                       love my card  B00IX1I3G6  B00IX1I3G6   \n",
      "97  itu2019s easy to use and very convenient i wou...  B086KKT3RX  B086KKT3RX   \n",
      "98    very easy to use i wish i knew about it earlier  B00IX1I3G6  B00IX1I3G6   \n",
      "99                           sent in lovely container  B01K8RJDEI  B00ADR2LV6   \n",
      "\n",
      "                         user_id     timestamp  helpful_vote  \\\n",
      "0   AHZ6XMOLEWA67S3TX7IWEXXGWSOA  1.549870e+12             0   \n",
      "1   AFZUK3MTBIBEDQOPAK3OATUOUKLA  1.599880e+12             0   \n",
      "2   AFZUK3MTBIBEDQOPAK3OATUOUKLA  1.535940e+12            27   \n",
      "3   AFZUK3MTBIBEDQOPAK3OATUOUKLA  1.418440e+12             0   \n",
      "4   AH5L7ILVA6HYLZOUZIQAWNHVVK3A  1.638070e+12             2   \n",
      "..                           ...           ...           ...   \n",
      "95  AFQW7QX2DREMFPK5WSMQKG27UOQA  1.672950e+12            17   \n",
      "96  AG6K7GPCDHQNKMVDMTYKKWSOAVVQ  1.515200e+12             0   \n",
      "97  AFGDRVPCP742YM5MMLFIKZCGNNRQ  1.640900e+12             0   \n",
      "98  AFGDRVPCP742YM5MMLFIKZCGNNRQ  1.593400e+12             0   \n",
      "99  AFWAXSLBIVNLLSKAKEXZWH6ZRFIQ  1.637790e+12             0   \n",
      "\n",
      "    verified_purchase  \n",
      "0                True  \n",
      "1               False  \n",
      "2                True  \n",
      "3               False  \n",
      "4                True  \n",
      "..                ...  \n",
      "95               True  \n",
      "96               True  \n",
      "97               True  \n",
      "98               True  \n",
      "99               True  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "def preprocesar_texto(texto):\n",
    "  tokens = word_tokenize(texto.lower())\n",
    "    \n",
    "  stop_words = set(stopwords.words('spanish'))\n",
    "  tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "  return ' '.join(tokens)\n",
    "\n",
    "df['title'] = df['title'].apply(preprocesar_texto)\n",
    "df['text'] = df['text'].apply(preprocesar_texto)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6639585c-8f82-452b-8e97-2a7731a93c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.9\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.30      0.33      0.32        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df['title'])\n",
    "y = df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fddd20-abe0-4708-baae-ffe5925aa5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c5fe6d-30f4-4f86-ba4b-46085ea25a46",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (452721253.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mhttps://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37605550-7250-4eb7-a9d9-c6f369272cf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [106 lines of output]\n",
      "  Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-75.8.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "  Collecting cython<3.0,>=0.25\n",
      "    Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "  Collecting cymem<2.1.0,>=2.0.2\n",
      "    Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "  Collecting preshed<3.1.0,>=3.0.2\n",
      "    Using cached preshed-3.0.9.tar.gz (14 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting murmurhash<1.1.0,>=0.28.0\n",
      "    Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "  Collecting thinc<8.4.0,>=8.3.0\n",
      "    Using cached thinc-8.3.2.tar.gz (193 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: still running...\n",
      "    Installing build dependencies: finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    pip subprocess to install build dependencies did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [67 lines of output]\n",
      "    Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "    Collecting setuptools\n",
      "      Using cached setuptools-75.8.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "    Collecting cython<3.0,>=0.25\n",
      "      Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "    Collecting murmurhash<1.1.0,>=1.0.2\n",
      "      Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "    Collecting cymem<2.1.0,>=2.0.2\n",
      "      Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "    Collecting preshed<3.1.0,>=3.0.2\n",
      "      Using cached preshed-3.0.9.tar.gz (14 kB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'done'\n",
      "      Getting requirements to build wheel: started\n",
      "      Getting requirements to build wheel: finished with status 'done'\n",
      "      Preparing metadata (pyproject.toml): started\n",
      "      Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "    Collecting blis<1.1.0,>=1.0.0\n",
      "      Using cached blis-1.0.2-cp313-cp313-win_amd64.whl.metadata (7.8 kB)\n",
      "    Collecting numpy<2.1.0,>=2.0.0\n",
      "      Using cached numpy-2.0.2.tar.gz (18.9 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'done'\n",
      "      Getting requirements to build wheel: started\n",
      "      Getting requirements to build wheel: finished with status 'done'\n",
      "      Installing backend dependencies: started\n",
      "      Installing backend dependencies: finished with status 'done'\n",
      "      Preparing metadata (pyproject.toml): started\n",
      "      Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "      error: subprocess-exited-with-error\n",
      "  \n",
      "      Preparing metadata (pyproject.toml) did not run successfully.\n",
      "      exit code: 1\n",
      "  \n",
      "      [21 lines of output]\n",
      "      + C:\\Users\\DELL\\.conda\\envs\\tarea\\python.exe C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-wce9hfg4\\numpy_c329ebf2b5194a17a939f0ed68fc4130\\vendored-meson\\meson\\meson.py setup C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-wce9hfg4\\numpy_c329ebf2b5194a17a939f0ed68fc4130 C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-wce9hfg4\\numpy_c329ebf2b5194a17a939f0ed68fc4130\\.mesonpy-jod99sw7 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-wce9hfg4\\numpy_c329ebf2b5194a17a939f0ed68fc4130\\.mesonpy-jod99sw7\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.4.99\n",
      "      Source dir: C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-wce9hfg4\\numpy_c329ebf2b5194a17a939f0ed68fc4130\n",
      "      Build dir: C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-wce9hfg4\\numpy_c329ebf2b5194a17a939f0ed68fc4130\\.mesonpy-jod99sw7\n",
      "      Build type: native build\n",
      "      Project name: NumPy\n",
      "      Project version: 2.0.2\n",
      "      WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "  \n",
      "      ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "      The following exception(s) were encountered:\n",
      "      Running `icl \"\"` gave \"[WinError 2] El sistema no puede encontrar el archivo especificado\"\n",
      "      Running `cl /?` gave \"[WinError 2] El sistema no puede encontrar el archivo especificado\"\n",
      "      Running `cc --version` gave \"[WinError 2] El sistema no puede encontrar el archivo especificado\"\n",
      "      Running `gcc --version` gave \"[WinError 2] El sistema no puede encontrar el archivo especificado\"\n",
      "      Running `clang --version` gave \"[WinError 2] El sistema no puede encontrar el archivo especificado\"\n",
      "      Running `clang-cl /?` gave \"[WinError 2] El sistema no puede encontrar el archivo especificado\"\n",
      "      Running `pgcc --version` gave \"[WinError 2] El sistema no puede encontrar el archivo especificado\"\n",
      "  \n",
      "      A full log can be found at C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-wce9hfg4\\numpy_c329ebf2b5194a17a939f0ed68fc4130\\.mesonpy-jod99sw7\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "      note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "    error: metadata-generation-failed\n",
      "  \n",
      "    Encountered error while generating package metadata.\n",
      "  \n",
      "    See above for output.\n",
      "  \n",
      "    note: This is an issue with the package mentioned above, not pip.\n",
      "    hint: See above for details.\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install build dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214b196d-58b9-4165-b66c-174e879e428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0e9dd4-1c0e-49dd-ab0a-ee5b4a5a3e88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def preprocesar_texto(texto):\n",
    "    doc = nlp(texto)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
    "\n",
    "textos = df['text'].tolist()  # Extract the 'text' column as a list \n",
    "textos_procesados = [preprocesar_texto(texto) for texto in textos]\n",
    "rating = df['rating']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(textos_procesados)\n",
    "y = rating\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "modelo = SVC(kernel='linear')\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(y_pred)\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85303828-7e67-471b-8698-a8a13305f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\.conda\\envs\\tarea\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.1 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb90923-adf6-4dc5-9315-c84be0ffb0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyTorch\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: PyTorch\n",
      "  Building wheel for PyTorch (setup.py): started\n",
      "  Building wheel for PyTorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for PyTorch\n",
      "Failed to build PyTorch\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      \u001b[31mexec\u001b[0m\u001b[1;31m(compile('''\u001b[0m\n",
      "      \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;31m# This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "      \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "      ...<31 lines>...\n",
      "      \u001b[1;31mexec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "      \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;31m''' % ('C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oluf2u0h\\\\pytorch_e11063c51a1a4b268d95f30051b39fe2\\\\setup.py',), \"<pip-setuptools-caller>\", \"exec\"))\u001b[0m\n",
      "      \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"<pip-setuptools-caller>\"\u001b[0m, line \u001b[35m34\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-oluf2u0h\\pytorch_e11063c51a1a4b268d95f30051b39fe2\\setup.py\"\u001b[0m, line \u001b[35m15\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      raise Exception(message)\n",
      "  \u001b[1;35mException\u001b[0m: \u001b[35mYou tried to install \"pytorch\". The package named for PyTorch is \"torch\"\u001b[0m\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for PyTorch\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (PyTorch)\n"
     ]
    }
   ],
   "source": [
    "pip install PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbba3c14-57bc-4b6f-af2f-6cbbe9a041e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\.conda\\envs\\tarea\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sentiment_analysis = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentiment-analysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnlptown/bert-base-multilingual-uncased-sentiment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m title = df[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m      6\u001b[39m resultados = sentiment_analysis(title)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\tarea\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:940\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    939\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    950\u001b[39m model_config = model.config\n\u001b[32m    951\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\tarea\\Lib\\site-packages\\transformers\\pipelines\\base.py:241\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[32m    217\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    238\u001b[39m \u001b[33;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    242\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    247\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_from_pipeline\u001b[39m\u001b[33m\"\u001b[39m] = task\n",
      "\u001b[31mRuntimeError\u001b[39m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "title = df['title'].tolist()\n",
    "resultados = sentiment_analysis(title)\n",
    "\n",
    "for texto, resultado in zip(title, resultados):\n",
    "    print(f\"Texto: {texto}\")\n",
    "    print(f\"Sentimiento: {resultado['label']} (Score: {resultado['score']:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee66d8-2db0-41ff-8fbe-ca50cb337f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
